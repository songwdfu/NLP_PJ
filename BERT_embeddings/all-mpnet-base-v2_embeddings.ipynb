{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_name = 'all-mpnet-base-v2'\n",
    "model_path = '/sbert_embeddings/all-mpnet-base-v2'\n",
    "model = SentenceTransformer(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"Hello world!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings = model.encode(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deal with fnc data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_train = pkl.load(open('/gpt_embeddings/stance_train.pkl','rb'))\n",
    "\n",
    "body_train = pkl.load(open('/gpt_embeddings/body_train.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_train = head_train[['Headline', 'Body ID', 'Stance', 'sentences']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_train = body_train[['Body ID', 'articleBody', 'sentences']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(sent):\n",
    "    return model.encode(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_train['embeddings'] = body_train['sentences'].apply(get_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body ID</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>sentences</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "      <td>[A small meteorite crashed into a wooded area ...</td>\n",
       "      <td>[[0.029839752, -0.030218968, 0.003450515, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Last week we hinted at what was to come as Ebo...</td>\n",
       "      <td>[Last week we hinted at what was to come as Eb...</td>\n",
       "      <td>[[0.011723922, 0.073492385, -0.02383645, -0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>(NEWSER) – Wonder how long a Quarter Pounder w...</td>\n",
       "      <td>[(NEWSER) – Wonder how long a Quarter Pounder ...</td>\n",
       "      <td>[[-0.020041967, 0.102185205, 0.0074368543, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Posting photos of a gun-toting child online, I...</td>\n",
       "      <td>[Posting photos of a gun-toting child online, ...</td>\n",
       "      <td>[[0.025258487, -0.0028769402, 0.028513137, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>At least 25 suspected Boko Haram insurgents we...</td>\n",
       "      <td>[At least 25 suspected Boko Haram insurgents w...</td>\n",
       "      <td>[[0.01621298, -0.0558657, -0.001334133, -0.015...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Body ID                                        articleBody  \\\n",
       "0        0  A small meteorite crashed into a wooded area i...   \n",
       "1        4  Last week we hinted at what was to come as Ebo...   \n",
       "2        5  (NEWSER) – Wonder how long a Quarter Pounder w...   \n",
       "3        6  Posting photos of a gun-toting child online, I...   \n",
       "4        7  At least 25 suspected Boko Haram insurgents we...   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  [A small meteorite crashed into a wooded area ...   \n",
       "1  [Last week we hinted at what was to come as Eb...   \n",
       "2  [(NEWSER) – Wonder how long a Quarter Pounder ...   \n",
       "3  [Posting photos of a gun-toting child online, ...   \n",
       "4  [At least 25 suspected Boko Haram insurgents w...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [[0.029839752, -0.030218968, 0.003450515, 0.02...  \n",
       "1  [[0.011723922, 0.073492385, -0.02383645, -0.08...  \n",
       "2  [[-0.020041967, 0.102185205, 0.0074368543, 0.0...  \n",
       "3  [[0.025258487, -0.0028769402, 0.028513137, -0....  \n",
       "4  [[0.01621298, -0.0558657, -0.001334133, -0.015...  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_train['embeddings'] = head_train['sentences'].apply(get_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body ID</th>\n",
       "      <th>Stance</th>\n",
       "      <th>sentences</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Police find mass graves with at least '15 bodi...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>[Police find mass graves with at least '15 bod...</td>\n",
       "      <td>[[0.009808279, 0.023274213, 0.02566386, 0.0317...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
       "      <td>158</td>\n",
       "      <td>agree</td>\n",
       "      <td>[Hundreds of Palestinians flee floods in Gaza ...</td>\n",
       "      <td>[[-0.0656245, 0.042460594, -0.022362517, -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christian Bale passes on role of Steve Jobs, a...</td>\n",
       "      <td>137</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>[Christian Bale passes on role of Steve Jobs, ...</td>\n",
       "      <td>[[-0.010717051, -0.0053509274, -0.0064408863, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HBO and Apple in Talks for $15/Month Apple TV ...</td>\n",
       "      <td>1034</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>[HBO and Apple in Talks for $15/Month Apple TV...</td>\n",
       "      <td>[[-0.03046375, 0.029996512, 0.019490862, -0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spider burrowed through tourist's stomach and ...</td>\n",
       "      <td>1923</td>\n",
       "      <td>disagree</td>\n",
       "      <td>[Spider burrowed through tourist's stomach and...</td>\n",
       "      <td>[[0.01663362, -0.04078897, 0.009623327, 0.0032...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body ID     Stance  \\\n",
       "0  Police find mass graves with at least '15 bodi...      712  unrelated   \n",
       "1  Hundreds of Palestinians flee floods in Gaza a...      158      agree   \n",
       "2  Christian Bale passes on role of Steve Jobs, a...      137  unrelated   \n",
       "3  HBO and Apple in Talks for $15/Month Apple TV ...     1034  unrelated   \n",
       "4  Spider burrowed through tourist's stomach and ...     1923   disagree   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  [Police find mass graves with at least '15 bod...   \n",
       "1  [Hundreds of Palestinians flee floods in Gaza ...   \n",
       "2  [Christian Bale passes on role of Steve Jobs, ...   \n",
       "3  [HBO and Apple in Talks for $15/Month Apple TV...   \n",
       "4  [Spider burrowed through tourist's stomach and...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [[0.009808279, 0.023274213, 0.02566386, 0.0317...  \n",
       "1  [[-0.0656245, 0.042460594, -0.022362517, -0.02...  \n",
       "2  [[-0.010717051, -0.0053509274, -0.0064408863, ...  \n",
       "3  [[-0.03046375, 0.029996512, 0.019490862, -0.08...  \n",
       "4  [[0.01663362, -0.04078897, 0.009623327, 0.0032...  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnc_train = head_train.merge(body_train, on='Body ID', suffixes=['_head', '_body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {'unrelated': 0, 'agree': 1, 'discuss': 2, 'disagree': 3}\n",
    "\n",
    "fnc_train['Stance'] = fnc_train['Stance'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnc_train['embeddings_head'] = fnc_train['embeddings_head'].apply(torch.tensor)\n",
    "fnc_train['embeddings_body'] = fnc_train['embeddings_body'].apply(torch.tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fnc_training encoding done, split and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnc_train_copy = fnc_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnc_train_copy_ = fnc_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "fnc_train, fnc_val = train_test_split(fnc_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(fnc_train, open('/sbert_embeddings/fnc_train.pkl','wb'))\n",
    "pkl.dump(fnc_val, open('/sbert_embeddings/fnc_val.pkl','wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get mean version of fnc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnc_train_copy['embeddings_head'] = fnc_train_copy['embeddings_head'].apply(lambda x: torch.mean(x, dim=0))\n",
    "fnc_train_copy['embeddings_body'] = fnc_train_copy['embeddings_body'].apply(lambda x: torch.mean(x, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "fnc_train_copy, fnc_val_copy= train_test_split(fnc_train_copy, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(fnc_train_copy, open('/sbert_embeddings/fnc_train_mean.pkl','wb'))\n",
    "pkl.dump(fnc_val_copy, open('/sbert_embeddings/fnc_val_mean.pkl','wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dealing with arc data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_body = pd.read_csv('/gpt_embeddings/pure_arc_body.csv')\n",
    "arc_head = pd.read_csv('/gpt_embeddings/pure_arc_stance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_body['sentences'] = arc_body['articleBody'].apply(sent_tokenize)\n",
    "arc_head['sentences'] = arc_head['Headline'].apply(sent_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_body['embeddings'] = arc_body['sentences'].apply(get_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_head['embeddings'] = arc_head['sentences'].apply(get_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_train = arc_head.merge(arc_body, on='Body ID', suffixes=['_head', '_body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {'unrelated': 0, 'agree': 1, 'discuss': 2, 'disagree': 3}\n",
    "\n",
    "arc_train['Stance'] = arc_train['Stance'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_train['embeddings_head'] = arc_train['embeddings_head'].apply(torch.tensor)\n",
    "arc_train['embeddings_body'] = arc_train['embeddings_body'].apply(torch.tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train = pd.concat([fnc_train_copy_, arc_train], axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "done with encoding, split and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_copy = total_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train, total_val = train_test_split(total_train, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(total_train, open('/sbert_embeddings/total_train.pkl','wb'))\n",
    "pkl.dump(total_val, open('/sbert_embeddings/total_val.pkl','wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the mean version of total_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_copy['embeddings_head'] = total_train_copy['embeddings_head'].apply(lambda x: torch.mean(x, dim=0))\n",
    "total_train_copy['embeddings_body'] = total_train_copy['embeddings_body'].apply(lambda x: torch.mean(x, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_copy, total_val_copy = train_test_split(total_train_copy, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(total_train_copy, open('/sbert_embeddings/total_train_mean.pkl','wb'))\n",
    "pkl.dump(total_val_copy, open('/sbert_embeddings/total_val_mean.pkl','wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deal with fnc test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_test = pd.read_csv(r'D:\\NLP_PJ\\fnc-1\\competition_test_bodies.csv')\n",
    "head_test = pd.read_csv(r'D:\\NLP_PJ\\fnc-1\\competition_test_stances.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_test['sentences'] = body_test['articleBody'].apply(sent_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_test['sentences'] = head_test['Headline'].apply(sent_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(sent):\n",
    "    return model.encode(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_test['embeddings'] = body_test['sentences'].apply(get_embedding)\n",
    "head_test['embeddings'] = head_test['sentences'].apply(get_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {'unrelated': 0, 'agree': 1, 'discuss': 2, 'disagree': 3}\n",
    "\n",
    "head_test['Stance'] = head_test['Stance'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnc_comp_test = head_test.merge(body_test, on='Body ID', suffixes=['_head', '_body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnc_comp_test['embeddings_body'] = fnc_comp_test['embeddings_body'].apply(torch.tensor)\n",
    "fnc_comp_test['embeddings_head'] = fnc_comp_test['embeddings_head'].apply(torch.tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "done with encoding, save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(fnc_comp_test, open('/sbert_embeddings/fnc_comp_test.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnc_comp_test_copy = fnc_comp_test.copy()\n",
    "trans = lambda x: torch.mean(x, dim=0)\n",
    "fnc_comp_test_copy['embeddings_head'] = fnc_comp_test_copy['embeddings_head'].apply(trans)\n",
    "fnc_comp_test_copy['embeddings_body'] = fnc_comp_test_copy['embeddings_body'].apply(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(fnc_comp_test_copy, open('/sbert_embeddings/fnc_comp_test_mean.pkl','wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
