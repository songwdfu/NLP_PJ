{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Song\\.conda\\envs\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import pickle as pkl\n",
    "import pandas\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_train = pkl.load(open('sentences/body_train.pkl','rb'))\n",
    "body_test = pkl.load(open('sentences/body_test.pkl','rb'))\n",
    "stance_train = pkl.load(open('sentences/stance_train.pkl','rb'))\n",
    "stance_test = pkl.load(open('sentences/stance_test.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained('gpt2', cache_dir='.cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_model = GPT2Model.from_pretrained('gpt2', cache_dir='.cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_model = gpt_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Model(\n",
       "  (wte): Embedding(50257, 768)\n",
       "  (wpe): Embedding(1024, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (8): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (9): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (10): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (11): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(sent):\n",
    "    input_ids = gpt_tokenizer.encode(sent, return_tensors='pt')\n",
    "    input_ids = input_ids.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = gpt_model(input_ids)\n",
    "        embeddings = outputs.last_hidden_state.detach().cpu()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = body_train['sentences'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_tokenizer.pad_token = gpt_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A small meteorite crashed into a wooded area in Nicaragua's capital of Managua overnight, the government said Sunday.\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A small meteorite crashed into a wooded area in Nicaragua's capital of Managua overnight, the government said Sunday.\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Residents reported hearing a mysterious boom that left a 16-foot deep crater near the city's airport, the Associated Press reports.\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9962], device='cuda:0')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cosine_similarity(b.unsqueeze(0), c.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"I'm a happy student studying in a university.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = sent[0]\n",
    "tokens = gpt_tokenizer.encode(sentence, add_special_tokens=True)\n",
    "\n",
    "input_ids = torch.tensor([tokens]).to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = gpt_model(input_ids)\n",
    "    last_hidden_state = outputs.last_hidden_state\n",
    "a = last_hidden_state.squeeze().mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = sent[1]\n",
    "tokens = gpt_tokenizer.encode(sentence, add_special_tokens=True)\n",
    "\n",
    "input_ids = torch.tensor([tokens]).to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = gpt_model(input_ids)\n",
    "    last_hidden_state = outputs.last_hidden_state\n",
    "b = last_hidden_state.squeeze().mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = s\n",
    "tokens = gpt_tokenizer.encode(sentence, add_special_tokens=True)\n",
    "\n",
    "input_ids = torch.tensor([tokens]).to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = gpt_model(input_ids)\n",
    "    last_hidden_state = outputs.last_hidden_state\n",
    "c = last_hidden_state.squeeze().mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_train['embeddings'] = body_train['sentences'].apply(get_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0667,  0.0881, -0.3085,  ...,  0.0307,  0.0512, -0.0019],\n",
       "         [ 0.0354,  0.0094,  0.0664,  ...,  0.0637, -0.1114, -0.0031],\n",
       "         [ 0.0202,  0.0210,  0.0979,  ...,  0.0937, -0.1037,  0.0063],\n",
       "         ...,\n",
       "         [ 0.0208,  0.0419,  0.1367,  ...,  0.0850, -0.1359, -0.0636],\n",
       "         [ 0.0212,  0.0393,  0.1369,  ...,  0.0841, -0.1380, -0.0664],\n",
       "         [ 0.0215,  0.0364,  0.1364,  ...,  0.0831, -0.1398, -0.0694]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_train['embeddings'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0667,  0.0881, -0.3085,  ...,  0.0307,  0.0512, -0.0019],\n",
       "         [ 0.0354,  0.0094,  0.0664,  ...,  0.0637, -0.1114, -0.0031],\n",
       "         [ 0.0202,  0.0210,  0.0979,  ...,  0.0937, -0.1037,  0.0063],\n",
       "         [ 0.0209,  0.0301,  0.1139,  ...,  0.0987, -0.1048, -0.0023],\n",
       "         [ 0.0213,  0.0368,  0.1231,  ...,  0.1002, -0.1074, -0.0116]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_train['embeddings'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body ID</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>sentences</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A small meteorite crashed into a wooded area i...</td>\n",
       "      <td>[A small meteorite crashed into a wooded area ...</td>\n",
       "      <td>[[[tensor(-0.0667), tensor(0.0881), tensor(-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Last week we hinted at what was to come as Ebo...</td>\n",
       "      <td>[Last week we hinted at what was to come as Eb...</td>\n",
       "      <td>[[[tensor(-0.0667), tensor(0.0881), tensor(-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>(NEWSER) – Wonder how long a Quarter Pounder w...</td>\n",
       "      <td>[(NEWSER) – Wonder how long a Quarter Pounder ...</td>\n",
       "      <td>[[[tensor(-0.0667), tensor(0.0881), tensor(-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Posting photos of a gun-toting child online, I...</td>\n",
       "      <td>[Posting photos of a gun-toting child online, ...</td>\n",
       "      <td>[[[tensor(-0.0667), tensor(0.0881), tensor(-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>At least 25 suspected Boko Haram insurgents we...</td>\n",
       "      <td>[At least 25 suspected Boko Haram insurgents w...</td>\n",
       "      <td>[[[tensor(-0.0667), tensor(0.0881), tensor(-0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Body ID                                        articleBody  \\\n",
       "0        0  A small meteorite crashed into a wooded area i...   \n",
       "1        4  Last week we hinted at what was to come as Ebo...   \n",
       "2        5  (NEWSER) – Wonder how long a Quarter Pounder w...   \n",
       "3        6  Posting photos of a gun-toting child online, I...   \n",
       "4        7  At least 25 suspected Boko Haram insurgents we...   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  [A small meteorite crashed into a wooded area ...   \n",
       "1  [Last week we hinted at what was to come as Eb...   \n",
       "2  [(NEWSER) – Wonder how long a Quarter Pounder ...   \n",
       "3  [Posting photos of a gun-toting child online, ...   \n",
       "4  [At least 25 suspected Boko Haram insurgents w...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [[[tensor(-0.0667), tensor(0.0881), tensor(-0....  \n",
       "1  [[[tensor(-0.0667), tensor(0.0881), tensor(-0....  \n",
       "2  [[[tensor(-0.0667), tensor(0.0881), tensor(-0....  \n",
       "3  [[[tensor(-0.0667), tensor(0.0881), tensor(-0....  \n",
       "4  [[[tensor(-0.0667), tensor(0.0881), tensor(-0....  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_test['embeddings'] = body_test['sentences'].apply(get_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body ID</th>\n",
       "      <th>articleBody</th>\n",
       "      <th>sentences</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Al-Sisi has denied Israeli reports stating tha...</td>\n",
       "      <td>[Al-Sisi has denied Israeli reports stating th...</td>\n",
       "      <td>[[tensor(-0.0667), tensor(0.0881), tensor(-0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A bereaved Afghan mother took revenge on the T...</td>\n",
       "      <td>[A bereaved Afghan mother took revenge on the ...</td>\n",
       "      <td>[[tensor(-0.0667), tensor(0.0881), tensor(-0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CNBC is reporting Tesla has chosen Nevada as t...</td>\n",
       "      <td>[CNBC is reporting Tesla has chosen Nevada as ...</td>\n",
       "      <td>[[tensor(-0.0667), tensor(0.0881), tensor(-0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>A 4-inch version of the iPhone 6 is said to be...</td>\n",
       "      <td>[A 4-inch version of the iPhone 6 is said to b...</td>\n",
       "      <td>[[tensor(-0.0667), tensor(0.0881), tensor(-0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>GR editor’s Note\\r\\n\\r\\nThere are no reports i...</td>\n",
       "      <td>[GR editor’s Note\\r\\n\\r\\nThere are no reports ...</td>\n",
       "      <td>[[tensor(-0.0667), tensor(0.0881), tensor(-0.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Body ID                                        articleBody  \\\n",
       "0        1  Al-Sisi has denied Israeli reports stating tha...   \n",
       "1        2  A bereaved Afghan mother took revenge on the T...   \n",
       "2        3  CNBC is reporting Tesla has chosen Nevada as t...   \n",
       "3       12  A 4-inch version of the iPhone 6 is said to be...   \n",
       "4       19  GR editor’s Note\\r\\n\\r\\nThere are no reports i...   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  [Al-Sisi has denied Israeli reports stating th...   \n",
       "1  [A bereaved Afghan mother took revenge on the ...   \n",
       "2  [CNBC is reporting Tesla has chosen Nevada as ...   \n",
       "3  [A 4-inch version of the iPhone 6 is said to b...   \n",
       "4  [GR editor’s Note\\r\\n\\r\\nThere are no reports ...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [[tensor(-0.0667), tensor(0.0881), tensor(-0.3...  \n",
       "1  [[tensor(-0.0667), tensor(0.0881), tensor(-0.3...  \n",
       "2  [[tensor(-0.0667), tensor(0.0881), tensor(-0.3...  \n",
       "3  [[tensor(-0.0667), tensor(0.0881), tensor(-0.3...  \n",
       "4  [[tensor(-0.0667), tensor(0.0881), tensor(-0.3...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stance_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_head_embedding(sent):\n",
    "    input_ids = gpt_tokenizer.encode(sent, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = gpt_model(input_ids)\n",
    "        embeddings = outputs.last_hidden_state\n",
    "    return embeddings.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stance_train['embeddings'] = stance_train['sentences'].apply(get_head_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body ID</th>\n",
       "      <th>Stance</th>\n",
       "      <th>sentences</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Police find mass graves with at least '15 bodi...</td>\n",
       "      <td>712</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>[Police find mass graves with at least '15 bod...</td>\n",
       "      <td>[[[tensor(-0.0667), tensor(0.0881), tensor(-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
       "      <td>158</td>\n",
       "      <td>agree</td>\n",
       "      <td>[Hundreds of Palestinians flee floods in Gaza ...</td>\n",
       "      <td>[[[tensor(-0.0667), tensor(0.0881), tensor(-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christian Bale passes on role of Steve Jobs, a...</td>\n",
       "      <td>137</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>[Christian Bale passes on role of Steve Jobs, ...</td>\n",
       "      <td>[[[tensor(-0.0667), tensor(0.0881), tensor(-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HBO and Apple in Talks for $15/Month Apple TV ...</td>\n",
       "      <td>1034</td>\n",
       "      <td>unrelated</td>\n",
       "      <td>[HBO and Apple in Talks for $15/Month Apple TV...</td>\n",
       "      <td>[[[tensor(-0.0667), tensor(0.0881), tensor(-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spider burrowed through tourist's stomach and ...</td>\n",
       "      <td>1923</td>\n",
       "      <td>disagree</td>\n",
       "      <td>[Spider burrowed through tourist's stomach and...</td>\n",
       "      <td>[[[tensor(-0.0667), tensor(0.0881), tensor(-0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body ID     Stance  \\\n",
       "0  Police find mass graves with at least '15 bodi...      712  unrelated   \n",
       "1  Hundreds of Palestinians flee floods in Gaza a...      158      agree   \n",
       "2  Christian Bale passes on role of Steve Jobs, a...      137  unrelated   \n",
       "3  HBO and Apple in Talks for $15/Month Apple TV ...     1034  unrelated   \n",
       "4  Spider burrowed through tourist's stomach and ...     1923   disagree   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  [Police find mass graves with at least '15 bod...   \n",
       "1  [Hundreds of Palestinians flee floods in Gaza ...   \n",
       "2  [Christian Bale passes on role of Steve Jobs, ...   \n",
       "3  [HBO and Apple in Talks for $15/Month Apple TV...   \n",
       "4  [Spider burrowed through tourist's stomach and...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [[[tensor(-0.0667), tensor(0.0881), tensor(-0....  \n",
       "1  [[[tensor(-0.0667), tensor(0.0881), tensor(-0....  \n",
       "2  [[[tensor(-0.0667), tensor(0.0881), tensor(-0....  \n",
       "3  [[[tensor(-0.0667), tensor(0.0881), tensor(-0....  \n",
       "4  [[[tensor(-0.0667), tensor(0.0881), tensor(-0....  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stance_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stance_test['embeddings'] = stance_test['Headline'].apply(get_head_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body ID</th>\n",
       "      <th>sentences</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ferguson riots: Pregnant woman loses eye after...</td>\n",
       "      <td>2008</td>\n",
       "      <td>[Ferguson riots: Pregnant woman loses eye afte...</td>\n",
       "      <td>[[[tensor(-0.0748), tensor(-0.1390), tensor(-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crazy Conservatives Are Sure a Gitmo Detainee ...</td>\n",
       "      <td>1550</td>\n",
       "      <td>[Crazy Conservatives Are Sure a Gitmo Detainee...</td>\n",
       "      <td>[[[tensor(-0.1905), tensor(-0.0578), tensor(-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Russian Guy Says His Justin Bieber Ringtone ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[A Russian Guy Says His Justin Bieber Ringtone...</td>\n",
       "      <td>[[[tensor(-0.1422), tensor(-0.0903), tensor(-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zombie Cat: Buried Kitty Believed Dead, Meows ...</td>\n",
       "      <td>1793</td>\n",
       "      <td>[Zombie Cat: Buried Kitty Believed Dead, Meows...</td>\n",
       "      <td>[[[tensor(-0.2125), tensor(-0.0637), tensor(-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Argentina's President Adopts Boy to End Werewo...</td>\n",
       "      <td>37</td>\n",
       "      <td>[Argentina's President Adopts Boy to End Werew...</td>\n",
       "      <td>[[[tensor(-0.0847), tensor(-0.1937), tensor(-0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline  Body ID  \\\n",
       "0  Ferguson riots: Pregnant woman loses eye after...     2008   \n",
       "1  Crazy Conservatives Are Sure a Gitmo Detainee ...     1550   \n",
       "2  A Russian Guy Says His Justin Bieber Ringtone ...        2   \n",
       "3  Zombie Cat: Buried Kitty Believed Dead, Meows ...     1793   \n",
       "4  Argentina's President Adopts Boy to End Werewo...       37   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  [Ferguson riots: Pregnant woman loses eye afte...   \n",
       "1  [Crazy Conservatives Are Sure a Gitmo Detainee...   \n",
       "2  [A Russian Guy Says His Justin Bieber Ringtone...   \n",
       "3  [Zombie Cat: Buried Kitty Believed Dead, Meows...   \n",
       "4  [Argentina's President Adopts Boy to End Werew...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [[[tensor(-0.0748), tensor(-0.1390), tensor(-0...  \n",
       "1  [[[tensor(-0.1905), tensor(-0.0578), tensor(-0...  \n",
       "2  [[[tensor(-0.1422), tensor(-0.0903), tensor(-0...  \n",
       "3  [[[tensor(-0.2125), tensor(-0.0637), tensor(-0...  \n",
       "4  [[[tensor(-0.0847), tensor(-0.1937), tensor(-0...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stance_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(body_test, open('gpt_embeddings/body_test.pkl', 'wb+'))\n",
    "pkl.dump(body_train, open('gpt_embeddings/body_train.pkl', 'wb+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(stance_train, open('gpt_embeddings/stance_train.pkl', 'wb+'))\n",
    "pkl.dump(stance_test, open('gpt_embeddings/stance_test.pkl', 'wb+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
